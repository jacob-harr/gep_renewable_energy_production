{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEP Results Preview\n",
    "\n",
    "This script visualizes results from run_renewable_energy_production.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dirs\n",
    "data_dir = '../data'\n",
    "input_dir = os.path.join(data_dir, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_gep_in_directory(input_dir):\n",
    "    # Get a list of CSV files in the directory\n",
    "    csv_files = glob.glob(os.path.join(input_dir, \"*.csv\"))\n",
    "    \n",
    "    # Loop through each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Check if the required columns exist\n",
    "        required_cols = {'Year', 'gep', 'Country_Name'}\n",
    "        if not required_cols.issubset(df.columns):\n",
    "            print(f\"Skipping file {csv_file}: required columns {required_cols} missing.\")\n",
    "            continue\n",
    "        \n",
    "        summary_records = []\n",
    "        \n",
    "        # Group the DataFrame by 'Year'\n",
    "        for year, group in df.groupby('Year'):\n",
    "            # Convert the 'gep' column to a NumPy array\n",
    "            gep_values = group['gep'].values\n",
    "            # Get the array of countries for indexing\n",
    "            countries = group['Country_Name'].values\n",
    "            \n",
    "            # Count the number of unique countries for the year\n",
    "            num_countries = group['Country_Name'].nunique()\n",
    "            \n",
    "            # Compute summary statistics using NumPy\n",
    "            max_gep = np.max(gep_values)\n",
    "            max_idx = np.argmax(gep_values)\n",
    "            max_country = countries[max_idx]\n",
    "            \n",
    "            min_gep = np.min(gep_values)\n",
    "            min_idx = np.argmin(gep_values)\n",
    "            min_country = countries[min_idx]\n",
    "            \n",
    "            med_gep = np.median(gep_values)\n",
    "            # For median country, find the index where the value is closest to the median\n",
    "            median_idx = np.argmin(np.abs(gep_values - med_gep))\n",
    "            median_country = countries[median_idx]\n",
    "            \n",
    "            total_gep = np.sum(gep_values)\n",
    "            \n",
    "            # Append the summary statistics in the specified order\n",
    "            summary_records.append({\n",
    "                'Year': year,\n",
    "                'num_countries': num_countries,\n",
    "                'max_gep': max_gep,\n",
    "                'min_gep': min_gep,\n",
    "                'med_gep': med_gep,\n",
    "                'total_gep': total_gep,\n",
    "                'max_country': max_country,\n",
    "                'min_country': min_country,\n",
    "                'median_country': median_country\n",
    "            })\n",
    "        \n",
    "        # Create a DataFrame from the summary records and order columns accordingly\n",
    "        summary_df = pd.DataFrame(summary_records)\n",
    "        summary_df = summary_df[['Year', 'num_countries', 'max_gep', 'min_gep', \n",
    "                                 'med_gep', 'total_gep', 'max_country', 'min_country', \n",
    "                                 'median_country']]\n",
    "        \n",
    "        # set output dir\n",
    "        out_dir = os.path.join(data_dir, 'summary')\n",
    "        if out_dir:\n",
    "            os.makedirs(out_dir, exist_ok=True) # create dir if needed\n",
    "\n",
    "        # Build the output filename using the first three letters of the input filename\n",
    "        base_filename = os.path.basename(csv_file)\n",
    "        first_three = base_filename[:3]\n",
    "        output_filename = f\"{first_three}_summary.csv\"\n",
    "        output_path = os.path.join(out_dir, output_filename)\n",
    "        \n",
    "        summary_df.to_csv(output_path, index=False)\n",
    "        print(f\"Summary saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to ../data/summary/geo_summary.csv\n",
      "Summary saved to ../data/summary/sol_summary.csv\n",
      "Summary saved to ../data/summary/win_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# call summarize function\n",
    "summarize_gep_in_directory(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
